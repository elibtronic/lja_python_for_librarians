{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python for Librarians - Week 4 Homework\n",
    "\n",
    "## Machine Learing Madness\n",
    "\n",
    "We are going to take our new knowledge of ML and apply it to a different dataset. This week we are going to look at a concatenated version of this [dataset](https://datadryad.org/stash/dataset/doi:10.5061/dryad.2h4j5). Let's see if you can infer what our model features and target will be once we look at the columns. As with all of our examples this data has been slightly modified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#We'll draw a graph later on\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "#Our 'Machine Learning pieces'\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import export_text\n",
    "from sklearn import metrics \n",
    "from sklearn import tree\n",
    "\n",
    "\n",
    "#Suppress the distracting warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load up our data\n",
    "citation_data = pd.read_csv(\"https://raw.githubusercontent.com/elibtronic/lja_datasets/master/week_4_homework_citation.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run this cell a few times to get a look at the data\n",
    "citation_data.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "citation_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our data is ~1300 lines from the original dataset with the following columns:\n",
    "\n",
    "- Score1 - a score assigned by assesor 1\n",
    "- Score2 - a score assigned by assessor 2\n",
    "- IF2 - the two year impact factor score \n",
    "- IF5 - the five year impact factor score\n",
    "- TopCitation - If the citation is among the top 10% of all citations in this dataset\n",
    "\n",
    "We are going to build a Decision Tree Classifer ML model that will see if we can predict if a citation will be in the top 10% of all cited articles in this dataset.\n",
    "\n",
    "This seems like an esoteric question to ask and answer? Yes, I'll give you that. We are trying to see if 4 different 'scores' can be used to determine what class we can put a citation in: The top 10% (or very imporant) versus the bottom 90% (citations we can ignore because the don't score high)\n",
    "\n",
    "We are also going to see how accurate we can get a model by tweaking some parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1\n",
    "\n",
    "In the next cell uncomment the correct lines to identify the features and the targets that this model will be built with. You need to uncomment 1 line between lines: 3 & 10 and uncomment one line between lines: 14 & 18."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Which set of columns will be our features?\n",
    "\n",
    "#citation_features = [\"Score1\"]\n",
    "#citation_features = [\"Score1\",\"Score2\",\"IF2\",\"IF5\",\"TopCitation\"]\n",
    "#citation_features = [\"Score1\",\"Score2\"]\n",
    "#citation_features = [\"Score1\",\"Score2\",\"IF2\",\"IF5\"]\n",
    "#citation_features = [\"Score1\",\"Score2\",\"IF2\"]\n",
    "#citation_features = [\"TopCitation\"]\n",
    "#citation_features = [\"TopCitation\",\"Score1\"]\n",
    "#citation_features = [\"TopCitation\",\"IF2\",\"IF5\"]\n",
    "\n",
    "#Which column will be our target?\n",
    "\n",
    "#citation_target = [\"Score1\"]\n",
    "#citation_target = [\"Score2\"]\n",
    "#citation_target = [\"IF2\"]\n",
    "#citation_target = [\"IF5\"]\n",
    "#citation_target = [\"TopCitation\"]\n",
    "\n",
    "X = citation_data[citation_features]\n",
    "y = citation_data[citation_target]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the next cell to build the Decision Tree Classifier model and get the accuracy of the model using our basic set of parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We'll start with 20 just for fun\n",
    "test_percent = 20\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \\\n",
    "                                                    y, \\\n",
    "                                                    test_size=test_percent/100.0)\n",
    "# Create Decision Tree classifer object\n",
    "treeClass = DecisionTreeClassifier()\n",
    "\n",
    "# Train\n",
    "treeClass = treeClass.fit(X_train,y_train)\n",
    "\n",
    "#Predict\n",
    "y_pred = treeClass.predict(X_test)\n",
    "\n",
    "#Accuracy?\n",
    "print(\"Accuracy of our model: \")\n",
    "metrics.accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing our tree\n",
    "\n",
    "Let's have a look at the tree we created without changing any hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "printed_tree = export_text(treeClass,feature_names=citation_features)\n",
    "print(printed_tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2\n",
    "\n",
    "Not bad. What accuracy did you expect the model to have?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I thought the accuracy was going to be ...\n",
    "\n",
    "I though this because..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q3\n",
    "\n",
    "Let's see what effect changing the testing percent has on accuracy. In the cell below add some values in the `test_percents` list to test this and view the corresponding graph. You need to modify line 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add some values between 1 - 99 in a comman separated list in the next line\n",
    "#write them in increasing order\n",
    "testing_percents = [,,,,]\n",
    "\n",
    "accuracy = []\n",
    "training_percents = []\n",
    "\n",
    "for test_ratio in testing_percents:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, \\\n",
    "                                                        y, \\\n",
    "                                                        test_size=test_ratio/100.0)\n",
    "    treeClassTest = DecisionTreeClassifier()\n",
    "    treeClassTest = treeClassTest.fit(X_train,y_train)\n",
    "    y_pred = treeClassTest.predict(X_test)\n",
    "    score = metrics.accuracy_score(y_test,y_pred)\n",
    "    accuracy.append(score)\n",
    "    training_percents.append(100 - test_ratio)\n",
    "\n",
    "    \n",
    "plt.plot(training_percents,accuracy)\n",
    "plt.ylabel(\"Accuracy in %\")\n",
    "plt.xlabel(\"Training Size %\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q4\n",
    "\n",
    "Let's wee what effect changing the maximum depth has on accuracy. In the cell below add some values in the max_options list to test this and view the corresponding graph. You need to modify line 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We'll fix this at 20% for this investigation\n",
    "test_percent = 20\n",
    "\n",
    "#add some values between 1 - 30 in a comma separated list in the next line\n",
    "#write them in increasing order\n",
    "max_options = [,,,,]\n",
    "\n",
    "accuracy = []\n",
    "tree_max = []\n",
    "\n",
    "for max_d in max_options:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, \\\n",
    "                                                        y, \\\n",
    "                                                        test_size=test_percent/100.0)\n",
    "    \n",
    "    #We set maximum depth in the DecisionTreeClassifer when we first create the variable\n",
    "    treeClassTest = DecisionTreeClassifier(max_depth=max_d)\n",
    "    treeClassTest = treeClassTest.fit(X_train,y_train)\n",
    "    y_pred = treeClassTest.predict(X_test)\n",
    "    score = metrics.accuracy_score(y_test,y_pred)\n",
    "    accuracy.append(score)\n",
    "    tree_max.append(max_d)\n",
    "\n",
    "    \n",
    "plt.plot(max_options,accuracy)\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"Maximum Depth of Tree\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maximizing and minimizing our accuracy\n",
    "\n",
    "Use the cell below to answer Q4 & Q5. You can modify the values on line 2 & 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_percent = \n",
    "max_d = \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \\\n",
    "                                                    y, \\\n",
    "                                                    test_size=test_percent/100.0)\n",
    "    \n",
    "treeClassTest = DecisionTreeClassifier(max_depth=max_d)\n",
    "treeClassTest = treeClassTest.fit(X_train,y_train)\n",
    "y_pred = treeClassTest.predict(X_test)\n",
    "\n",
    "#Accuracy?\n",
    "print(\"Calculated accuracy: \")\n",
    "print(metrics.accuracy_score(y_test,y_pred))\n",
    "\n",
    "print(\"\\nTree generated\")\n",
    "printed_tree = export_text(treeClass,feature_names=citation_features)\n",
    "print(printed_tree)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q5\n",
    "\n",
    "What combination of parameters above led to the highest accuracy?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I got the highest accuracy by..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q6\n",
    "\n",
    "What combination of parameters above led to the lowest accuracy?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I got the lowest accuracy by..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From Trees to Forests\n",
    "\n",
    "We've explored the accuracy of our ML model when we just created one tree. Let's see if we can increase this with a forest of trees for our citation information. Try some different values in for the two parameters on line 1 and line 2 to answer Q7 & Q8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Pick a values between 1 and 99\n",
    "test_percent = \n",
    "#Pick a values between 10 - 50\n",
    "number_estimators = \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \\\n",
    "                                                    y, \\\n",
    "                                                    test_size=test_percent/100.0)\n",
    "\n",
    "#Create Random Classifier\n",
    "clf = RandomForestClassifier(n_estimators=number_estimators)\n",
    "\n",
    "#Train\n",
    "clf.fit(X_train,np.ravel(y_train))\n",
    "\n",
    "#Predict\n",
    "y_pred = clf.predict(X_train)\n",
    "\n",
    "#Accuracy\n",
    "print(\"Accuracy?\")\n",
    "print(metrics.accuracy_score(y_train,y_pred))\n",
    "\n",
    "\n",
    "#Visualize the first tree in this forest\n",
    "print(\"\\nFirst tree in this forest\")\n",
    "printed_tree = export_text(clf.estimators_[0],feature_names = citation_features)\n",
    "print(printed_tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q7\n",
    "\n",
    "What combination of `test_percent` and `number_estimators` led the highest accuracy?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I got the highest accuracy by..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q8\n",
    "\n",
    "What combination of `test_percent` and `number_estimators` led the lowest accuracy?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I got the lowest accuracy by..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Congratuations!\n",
    "\n",
    "You've now officially completed Python for Librarians! Be sure to complete the last three steps:\n",
    "\n",
    "- Save your notebook as PDF and upload\n",
    "- Share your completed notebook with `libraryjuicepresspython@gmail.com` so I can get a shared copy of your work.\n",
    "- Head over to the Week 4 Homework Forum to make your last post\n",
    "\n",
    "-----\n",
    "\n",
    "# Thanks! I hope you enjoyed this\n",
    "\n",
    "Thanks for taking this class and giving Python a try. I have put together all of the datasets I've used for this class in a [github repository](https://github.com/elibtronic/lja_datasets) Feel free to open up a fresh Google Collab notebook and load a CSV file to perform some analysis or to build some machine learning models. Please drop me a [line](https://twitter.com/elibtronic/) if you'd like to talk more about this topic or if you have notebook you'd like to share."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
