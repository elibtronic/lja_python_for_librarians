{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python for Librarians - Week 3 Workalong\n",
    "\n",
    "We are going to continue to built on last week's work by continuing our examination of Pandas. Then we will spend some time creating graphs using a Python library called [MatPlotLib](https://matplotlib.org/).\n",
    "\n",
    "In terms of our data, for for this week we are going to look up some SciHub usage data and compare the usage from two large Candian cities: Toronto and Montreal. Every once in a while SciHub will publish anonymized usage data with some geographic information associated with it. Our task will be to evaluate that data to see if we can find any interesting comparisons. This dataset is a truncated version of what is found [here](https://datadryad.org/stash/dataset/doi:10.5061/dryad.q447c). As we saw in our readings for this week this dataset has been analyzed by a researcher who published results in the  journal called _Science_.\n",
    "\n",
    "Topics we'll be exploring\n",
    "\n",
    "- The Pandas Library\n",
    "- Graphing with MatplotLib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading our Libraries\n",
    "\n",
    "Line 1 should look familar. Line 3 & 4 will load up Matplotlib. In particular we need to include line 4 because we are working within a Jupyter Notebook. (We don't need to know exact details of why this is necessary, in case you are curious this [page](https://stackoverflow.com/questions/43027980/purpose-of-matplotlib-inline) will explain it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "#We `import as plt` just like we did with Pandas to make it so we have to type less \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "#Suppress the distracting warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our dataset already has column information so we don't need to add that. We just use Pandas to load up the CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sci_hub_data = pandas.read_csv(\"https://raw.githubusercontent.com/elibtronic/lja_datasets/master/week_3_sci_hub_worksheet.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following cell a few times to display different random samples of 20 rows to get a sense of what is in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sci_hub_data.sample(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a brief description of the columns\n",
    "- **timestamp** date and time of the SciHub Access\n",
    "- **user_id** an anoymized label to gather all of the usage from the same user into a identifier that doesn't identify them directly\n",
    "- **doi_whole** The complete DOI of the item that was downloaded from SciHub\n",
    "- **doi_prefix** The prefix of the DOI. This value allows us determine which source originally published this article\n",
    "- **doi_suffix** The suffix of the DOI. Or in other words the complete DOI the the prefix removed.\n",
    "\n",
    "(More details on how a DOI is [constructed](https://www.crossref.org/education/member-setup/constructing-your-dois/) in case you're interested.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1 \n",
    "Can you **describe** the dataframe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sci_hub_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case there is not a lot quantitiative data we get out of calling this function on the dataframe. Contrast this to what we saw with the San Francisco data we saw in week 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at how this data is split. Or in other words, how many rows are Montreal usage, how many are Toronto usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# How is the data split?\n",
    "sci_hub_data.groupby(\"city\")[\"doi_whole\"].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "\n",
    "How many unique publishers are in this dataset? (Hint: each unique prefix will indicate another Publisher in this data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How mandy unique publishers are in the data?\n",
    "sci_hub_data[].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3\n",
    "\n",
    "How many unique users are in this dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unique users\n",
    "sci_hub_data[].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Brief comparisons\n",
    "\n",
    "The next two cells will give us some details about downloads per publisher for Toronto and Montreal.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here are selected a subset of data (with sci_hub_data[\"city\"] == \"Toronto\" )\n",
    "#We group those results by doi_prefix and then apply .count() to get the total count instead of\n",
    "#each line that matches the query\n",
    "sci_hub_data[sci_hub_data[\"city\"] == \"Toronto\"].groupby(\"doi_prefix\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Top publishers in Montreal\n",
    "#same rationale as the cell above but with Montreal in the selection criteria\n",
    "sci_hub_data[sci_hub_data[\"city\"] == \"Montreal\"].groupby(\"doi_prefix\").count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sorting \n",
    "\n",
    "The previous couple of cells were great to group the data but everything was ordered by **doi_prefix**. Say we want to sort our lists of publishers so we got the topic ten entries for each city. We can sort by adding:\n",
    "\n",
    "```\n",
    ".sort_values(by=COLUMNNAME,ascending=False)\n",
    "```\n",
    "\n",
    "to our dataframe where `COLUMNNAME` is the name of the column we want to sort by. If we want to list from smallest to largest we change the second part to `ascending=True`\n",
    "\n",
    "We'll also just grab the top ten results in our sorted by adding `head(10)` to our search. As we see above there are many publishers that only show up once or twice. We want just the top 10 occuring publishers.\n",
    "\n",
    "The code in the following cell is broken up over a few lines just to make it easier to read. I'm using that `\\` notation to accomplish this. We certainly don't need to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Top 10 in Toronto\n",
    "#We apply our new sort_values function\n",
    "#we finally apply .head(10) to just get the top ten lines of results\n",
    "sci_hub_data[sci_hub_data[\"city\"] == \"Toronto\"]\\\n",
    "            .groupby(\"doi_prefix\")\\\n",
    "            .count()\\\n",
    "            .sort_values(by='user_id',ascending=False)\\\n",
    "            .head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Top 10 in Montreal\n",
    "#Same as above but with Montreal data\n",
    "sci_hub_data[sci_hub_data[\"city\"] == \"Montreal\"].groupby(\"doi_prefix\").count().sort_values(by='user_id',ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmmm. Interesting the top downloaded publisher in both cities is **10.1016**\n",
    "\n",
    "### Important detail!\n",
    "\n",
    "We sort by the `user_id` column in the previous examples because we want to count how many times each publisher shows up in the data, not just count each line in our sort. That's a subtle difference I know. \n",
    "\n",
    "Experiement with changing `user_id` to different columns in the examples to solidify your understanding of this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing some results\n",
    "\n",
    "We are starting to get a sense of what the data has in it but let's see if we can create some visualizations. Enter Matplotlib. We are going to create some smaller pandas dataframes to make our data easier to read when we graph it. Load the following cell so that we make the example below a bit easier to read."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toronto_users = sci_hub_data[sci_hub_data[\"city\"] == \"Toronto\"]\n",
    "montreal_users = sci_hub_data[sci_hub_data[\"city\"] == \"Montreal\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Everybody loves pie!\n",
    "\n",
    "Let's start with a [Pie](https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.pie.html) graph. Try to read through the code in the cell below before clicking the play button to run it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data we want to use for our pie graph\n",
    "toronto_slice = toronto_users[\"user_id\"].count()\n",
    "montreal_slice = montreal_users[\"user_id\"].count()\n",
    "\n",
    "#We provide a list of all the values we want in our pie graph\n",
    "pie_data = [toronto_slice,montreal_slice]\n",
    "\n",
    "#We tell Matplot lib to draw a pie with our data\n",
    "plt.pie(pie_data)\n",
    "\n",
    "#We'll always end with this, this tells matplotlib we are ready to draw the graph\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Fancier pie \n",
    "\n",
    "Looks good but we are missing some labels. Compare the above MatPlotLib pie graph to the following to see what we have added. The general flow looks the same for any graph we make with MatPlotLib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toronto_slice = toronto_users[\"user_id\"].count()\n",
    "montreal_slice = montreal_users[\"user_id\"].count()\n",
    "\n",
    "pie_data = [toronto_slice,montreal_slice]\n",
    "\n",
    "#Labels for Pie graph as a list\n",
    "pie_labels = [\"Toronto\",\"Montreal\"]\n",
    "\n",
    "#Just as before but this time we add labels=pie_labels to add labels\n",
    "plt.pie(pie_data,labels=pie_labels)\n",
    "\n",
    "#Nifty title to describe to our pie\n",
    "plt.title(\"Toronto versus Montreal Downloads\")\n",
    "\n",
    "#Generate the pie\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complex pies\n",
    "\n",
    "Let's draw a pie of the top 10 publishers downloaded in Toronto. Let's start by getting just the name and download counts (this should look familar to our example from earlier) we just add `[\"user_id\"]` at the end of our statement to just get the values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toronto_top_publishers = sci_hub_data[sci_hub_data[\"city\"] == \"Toronto\"].groupby(\"doi_prefix\")\\\n",
    "                            .count()\\\n",
    "                            .sort_values(by='user_id',ascending=False)\\\n",
    "                            .head(10)[\"user_id\"]\n",
    "\n",
    "toronto_top_publishers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`toronto_top_publishers` is a Pandas Series which operates just like a dictionary! We can access the the two parts as illustrated in the following cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the publisher DOI prefix is stored in the index\n",
    "print(\"Publisher Info\")\n",
    "for i in toronto_top_publishers.index:\n",
    "    print(i)\n",
    "\n",
    "print(\"------\")\n",
    "print(\"Counts\")\n",
    "#the count associated with each publisher is stored in the data field\n",
    "for i in toronto_top_publishers.values:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Finally, let's make our Pie\n",
    "\n",
    "plt.pie(toronto_top_publishers.values, labels=toronto_top_publishers.index)\n",
    "\n",
    "plt.title(\"Top Ten Publishers downloaded in Toronto\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4\n",
    "\n",
    "See if you can now replicate this for the Montreal data in the next cell. You just need to modify lines 6 & 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "montreal_top_publishers = sci_hub_data[sci_hub_data[\"city\"] == \"Montreal\"].groupby(\"doi_prefix\")\\\n",
    "                            .count()\\\n",
    "                            .sort_values(by='user_id',ascending=False)\\\n",
    "                            .head(10)[\"user_id\"]\n",
    "\n",
    "plt.pie(, labels=.index)\n",
    "\n",
    "plt.title(\"\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Histograms\n",
    "\n",
    "The last topic for this week's work is [histograms](https://en.wikipedia.org/wiki/Histogram). They are great because they show us how often values land within a certain range. These ranges are often called bins or buckets. Check out the short write-up on [Kahn](https://www.khanacademy.org/math/statistics-probability/displaying-describing-data/quantitative-data-graphs/a/histograms-review) to brush up on these details if you need.\n",
    "\n",
    "In the next example we are going to create a historgram of how many downloads per user happen in Toronto for the top 100 users in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This should look similar to our Toronto example for publisher info\n",
    "#Here we we are grouping our Toronto data by \"user_id\", getting the count of that\n",
    "#Sorting it from highest to lowest and taking the top 100 results from that\n",
    "\n",
    "\n",
    "toronto_downloads_by_user = toronto_users.groupby('user_id')\\\n",
    "                            .count()\\\n",
    "                            .sort_values(by = \"doi_whole\", ascending=False)[\"doi_whole\"].head(100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#how many different buckets we'll put values into (try experimenting with different values)\n",
    "bins = 250\n",
    "\n",
    "#Now we plot it all out\n",
    "#When we ask for a histogram we need to provide 2 pieces of information, the data we want to distribute\n",
    "#and the number of bins to sort this data into\n",
    "#matplot lib does all the heavy calculations for us\n",
    "plt.hist(toronto_downloads_by_user, bins)\n",
    "\n",
    "#When we have a graph with X and Y axis we can add labels to them\n",
    "plt.ylabel(\"Number of Users\")\n",
    "plt.xlabel(\"Number of Downloads\")\n",
    "\n",
    "#Descriptive title\n",
    "plt.title(\"Downloads per user in Toronto\")\n",
    "\n",
    "#Generate our Graph\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow. It looks like most users in Toronto download somewhere between 0-100 papers. There is 1 user that downloaded over a 1000 papers!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5\n",
    "\n",
    "Let's try making a histogram for downloads per person in Montreal. Most of the code is written for you already. You just need to fill in lines: 7,9,12,13,16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "montreal_downloads_by_user = montreal_users.groupby('user_id')\\\n",
    "                            .count()\\\n",
    "                            .sort_values(by = \"doi_whole\", ascending=False)[\"doi_whole\"].head(100)\n",
    "\n",
    "\n",
    "#how many different buckets we'll put values into (try experimenting with different values)\n",
    "bins = \n",
    "\n",
    "plt.hist(, bins)\n",
    "\n",
    "#When we have a graph with X and Y axis we can add labels to them\n",
    "plt.ylabel(\"\")\n",
    "plt.xlabel(\"\")\n",
    "\n",
    "#Descriptive title\n",
    "plt.title(\"\")\n",
    "\n",
    "#Generate our Graph\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whaaa? There is a Montreal user that has downloaded over 60 times more than the highest user in Toronto. Wild."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Congrats!\n",
    "\n",
    "This has been a heavy week. We built up our knowledge of Pandas and introduced a graphing library. In all reality we have barely scratched the surface of what Pandas can do or the myriad different graphs that Matplotlib can generate. Head over to the **Homework Noteook** now to test out what you've learned."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
